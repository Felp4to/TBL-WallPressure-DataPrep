{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import partitioning as part\n",
    "# Aggiungi al sys.path\n",
    "sys.path.append(\"../preprocessing/npy\")\n",
    "import sampling as samp\n",
    "import normalizzation as norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config_name = \"configs_t_t.json\"\n",
    "filename = \"Channel1.csv\"\n",
    "file_path = os.path.join(\"../timeseries/B101\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurazioni caricate:\n",
      "config_1: id = 1\n",
      "config_2: id = 2\n",
      "config_3: id = 3\n",
      "config_4: id = 4\n",
      "config_5: id = 5\n",
      "config_6: id = 6\n",
      "config_7: id = 7\n",
      "config_8: id = 8\n",
      "config_9: id = 9\n",
      "config_10: id = 10\n"
     ]
    }
   ],
   "source": [
    "configs = None\n",
    "\n",
    "# Apri il file e carica i dati in una variabile\n",
    "with open(file_config_name, \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "\n",
    "# Ora configs contiene tutte le configurazioni\n",
    "print(\"Configurazioni caricate:\")\n",
    "for name, conf in configs.items():\n",
    "    print(f\"{name}: id = {conf['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale campioni: 23272\n",
      "Train set: X = (16290, 10), y = (16290,)\n",
      "Validation set: X = (3490, 10), y = (3490,)\n",
      "Test set: X = (3492, 10), y = (3492,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_1'\n",
      "Totale campioni: 12190\n",
      "Train set: X = (8533, 20), y = (8533,)\n",
      "Validation set: X = (1828, 20), y = (1828,)\n",
      "Test set: X = (1829, 20), y = (1829,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_2'\n",
      "Totale campioni: 5019\n",
      "Train set: X = (3513, 50), y = (3513,)\n",
      "Validation set: X = (752, 50), y = (752,)\n",
      "Test set: X = (754, 50), y = (754,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_3'\n",
      "Totale campioni: 2534\n",
      "Train set: X = (1773, 100), y = (1773,)\n",
      "Validation set: X = (380, 100), y = (380,)\n",
      "Test set: X = (381, 100), y = (381,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_4'\n",
      "Totale campioni: 1273\n",
      "Train set: X = (891, 200), y = (891,)\n",
      "Validation set: X = (190, 200), y = (190,)\n",
      "Test set: X = (192, 200), y = (192,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_5'\n",
      "Totale campioni: 28444\n",
      "Train set: X = (19910, 10), y = (19910,)\n",
      "Validation set: X = (4266, 10), y = (4266,)\n",
      "Test set: X = (4268, 10), y = (4268,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_6'\n",
      "Totale campioni: 36570\n",
      "Train set: X = (25599, 10), y = (25599,)\n",
      "Validation set: X = (5485, 10), y = (5485,)\n",
      "Test set: X = (5486, 10), y = (5486,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_7'\n",
      "Totale campioni: 51198\n",
      "Train set: X = (35838, 10), y = (35838,)\n",
      "Validation set: X = (7679, 10), y = (7679,)\n",
      "Test set: X = (7681, 10), y = (7681,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_8'\n",
      "Totale campioni: 127995\n",
      "Train set: X = (89596, 10), y = (89596,)\n",
      "Validation set: X = (19199, 10), y = (19199,)\n",
      "Test set: X = (19200, 10), y = (19200,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_9'\n",
      "Totale campioni: 255990\n",
      "Train set: X = (179193, 10), y = (179193,)\n",
      "Validation set: X = (38398, 10), y = (38398,)\n",
      "Test set: X = (38399, 10), y = (38399,)\n",
      "\n",
      "✅ Partizioni create e salvate in 'partitions/part_t_t_10'\n"
     ]
    }
   ],
   "source": [
    "for name, config in configs.items():\n",
    "    foldername = \"part_t_t_\" + str(config[\"id\"])\n",
    "    \n",
    "    # slicing and sampling\n",
    "    sliced_and_sampled_data = samp.sampling_csv(samp.slicing(file_path, config[\"dim_slice\"]), config[\"sampling\"])\n",
    "    sliced_and_sampled_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # normalizzation\n",
    "    time_series_normalized = norm.normalize_array(sliced_and_sampled_data)\n",
    "    #display(time_series_normalized)\n",
    "    \n",
    "    # generazione delle sequenze\n",
    "    X, y = part.generate_time_sequences(time_series_normalized, config)\n",
    "\n",
    "    # split delle partizioni\n",
    "    part.split_and_save_dataset(X, y, foldername, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
